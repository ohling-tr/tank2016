// RobotBuilder Version: 2.0
//
// This file was generated by RobotBuilder. It contains sections of
// code that are automatically generated and assigned by robotbuilder.
// These sections will be updated in the future when you export to
// Java from RobotBuilder. Do not put any code or make any change in
// the blocks indicating autogenerated code or it will be lost on an
// update. Deleting the comments indicating the section will prevent
// it from being updated in the future.


package org.usfirst.frc4662.Tank2016.subsystems;

import java.util.Comparator;

//import org.usfirst.frc4662.Tank2016.RobotMap;
//import org.usfirst.frc4662.Tank2016.commands.*;

//import java.nio.ByteBuffer;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import com.ni.vision.NIVision;
import com.ni.vision.VisionException;
import com.ni.vision.NIVision.Image;
import com.ni.vision.NIVision.ImageType;

import static edu.wpi.first.wpilibj.Timer.delay;

import edu.wpi.first.wpilibj.command.Subsystem;


/**
 *
 */
public class VisionByte extends Subsystem {

	public static String kDefaultCameraName = "cam0";

	  private static String ATTR_VIDEO_MODE = "AcquisitionAttributes::VideoMode";
	  private static String ATTR_WB_MODE = "CameraAttributes::WhiteBalance::Mode";
	  private static String ATTR_WB_VALUE = "CameraAttributes::WhiteBalance::Value";
	  private static String ATTR_EX_MODE = "CameraAttributes::Exposure::Mode";
	  private static String ATTR_EX_VALUE = "CameraAttributes::Exposure::Value";
	  private static String ATTR_BR_MODE = "CameraAttributes::Brightness::Mode";
	  private static String ATTR_BR_VALUE = "CameraAttributes::Brightness::Value";

	  public class WhiteBalance {
		    public static final int kFixedIndoor = 3000;
		    public static final int kFixedOutdoor1 = 4000;
		    public static final int kFixedOutdoor2 = 5000;
		    public static final int kFixedFluorescent1 = 5100;
		    public static final int kFixedFlourescent2 = 5200;
	  }

	  private Pattern m_reMode =
		      Pattern
		          .compile("(?<width>[0-9]+)\\s*x\\s*(?<height>[0-9]+)\\s+(?<format>.*?)\\s+(?<fps>[0-9.]+)\\s*fps");

	  private String m_name = kDefaultCameraName;
	  private int m_id = -1;
	  private boolean m_active = false;
	  private boolean m_useJpeg = true;
	  private boolean m_targetMode = false;
	  private int m_width = 320;
	  private int m_height = 240;
//	  private int m_fps = 30;
	  private int m_fps = 8; //per 2014 white paper
	  private String m_whiteBalance = "auto";
	  private int m_whiteBalanceValue = -1;
	  private String m_exposure = "auto";
	  private int m_exposureValue = -1;
	  private int m_brightness = 50;
//	  private boolean m_needSettingsUpdate = true;
	  
	  private Image m_frame = NIVision.imaqCreateImage(ImageType.IMAGE_RGB, 0);
	  
    // Put methods for controlling this subsystem
    // here. Call these from Commands.

  public VisionByte() {
    openCamera();
  }

  public VisionByte(String name) {
    m_name = name;
    openCamera();
  }

  public synchronized void openCamera() {
    if (m_id != -1)
      return; // Camera is already open
    for (int i = 0; i < 3; i++) {
      try {
        m_id =
            NIVision.IMAQdxOpenCamera(m_name,
                NIVision.IMAQdxCameraControlMode.CameraControlModeController);
      } catch (VisionException e) {
        if (i == 2)
          throw e;
        delay(2.0);
        continue;
      }
      break;
    }
  }
  
  		public synchronized void closeCamera() {
	    if (m_id == -1)
	      return;
	    NIVision.IMAQdxCloseCamera(m_id);
	    m_id = -1;
	  }

	  public synchronized void startCapture() {
	    if (m_id == -1 || m_active)
	      return;
	    NIVision.IMAQdxConfigureGrab(m_id);
	    NIVision.IMAQdxStartAcquisition(m_id);
	    m_active = true;
	  }

	  public synchronized void stopCapture() {
	    if (m_id == -1 || !m_active)
	      return;
	    NIVision.IMAQdxStopAcquisition(m_id);
	    NIVision.IMAQdxUnconfigureAcquisition(m_id);
	    m_active = false;
	  }

	  public synchronized void updateSettings() {
		    boolean wasActive = m_active;
		    // Stop acquistion, close and reopen camera
		    if (wasActive)
		      stopCapture();
		    if (m_id != -1)
		      closeCamera();
		    openCamera();

		    // Video Mode
		    NIVision.dxEnumerateVideoModesResult enumerated = NIVision.IMAQdxEnumerateVideoModes(m_id);
		    NIVision.IMAQdxEnumItem foundMode = null;
		    int foundFps = 1000;
		    for (NIVision.IMAQdxEnumItem mode : enumerated.videoModeArray) {
		      Matcher m = m_reMode.matcher(mode.Name);
		      if (!m.matches())
		        continue;
		      if (Integer.parseInt(m.group("width")) != m_width)
		        continue;
		      if (Integer.parseInt(m.group("height")) != m_height)
		        continue;
		      double fps = Double.parseDouble(m.group("fps"));
		      if (fps < m_fps)
		        continue;
		      if (fps > foundFps)
		        continue;
		      String format = m.group("format");
		      boolean isJpeg = format.equals("jpeg") || format.equals("JPEG");
		      if ((m_useJpeg && !isJpeg) || (!m_useJpeg && isJpeg))
		        continue;
		      foundMode = mode;
		      foundFps = (int) fps;
		    }
		    if (foundMode != null) {
		      System.out.println("found mode " + foundMode.Value + ": " + foundMode.Name);
		      if (foundMode.Value != enumerated.currentMode)
		        NIVision.IMAQdxSetAttributeU32(m_id, ATTR_VIDEO_MODE, foundMode.Value);
		    }

		    // White Balance
		    if (m_whiteBalance == "auto")
		      NIVision.IMAQdxSetAttributeString(m_id, ATTR_WB_MODE, "Auto");
		    else {
		      NIVision.IMAQdxSetAttributeString(m_id, ATTR_WB_MODE, "Manual");
		      if (m_whiteBalanceValue != -1)
		        NIVision.IMAQdxSetAttributeI64(m_id, ATTR_WB_VALUE, m_whiteBalanceValue);
		    }

		    // Exposure
		    if (m_exposure == "auto")
		      NIVision.IMAQdxSetAttributeString(m_id, ATTR_EX_MODE, "AutoAperaturePriority");
		    else {
		      NIVision.IMAQdxSetAttributeString(m_id, ATTR_EX_MODE, "Manual");
		      if (m_exposureValue != -1) {
//		        long minv = NIVision.IMAQdxGetAttributeMinimumI64(m_id, ATTR_EX_VALUE);
//		        long maxv = NIVision.IMAQdxGetAttributeMaximumI64(m_id, ATTR_EX_VALUE);
//		        long val = minv + (long) (((double) (maxv - minv)) * (((double) m_exposureValue) / 100.0));
		        NIVision.IMAQdxSetAttributeI64(m_id, ATTR_EX_VALUE, m_exposureValue);
		      }
		    }

		    // Brightness
		    NIVision.IMAQdxSetAttributeString(m_id, ATTR_BR_MODE, "Manual");
//		    long minv = NIVision.IMAQdxGetAttributeMinimumI64(m_id, ATTR_BR_VALUE);
//		    long maxv = NIVision.IMAQdxGetAttributeMaximumI64(m_id, ATTR_BR_VALUE);
//		    long val = minv + (long) (((double) (maxv - minv)) * (((double) m_brightness) / 100.0));
		    NIVision.IMAQdxSetAttributeI64(m_id, ATTR_BR_VALUE, m_brightness);

		    // Restart acquisition
		    if (wasActive)
		      startCapture();
		  }

    public void initDefaultCommand() {
 
//        setDefaultCommand(new TankDrive());

    }
 
//  set up driver viewable camera
    public void driverCamera(){
    	m_whiteBalance = "auto";
  	  	m_whiteBalanceValue = -1;
  	  	m_exposure = "auto";
  	  	m_exposureValue = -1;
  	  	m_brightness = 80;	
        updateSettings();
		m_targetMode = false;
    }
    
//  set up target viewable camera
    public void targetCamera(){
   		m_whiteBalance = "manual";
  		m_whiteBalanceValue = 2800;
   		m_exposure = "manual";
   		m_exposureValue = 10;
   		m_brightness = 30;	
   		updateSettings();
		m_targetMode = true;
     }
//  set up target viewable camera
    public void toggleTargetMode(){
    	if (m_targetMode == false) {
    		targetCamera();
    	} else {
    		driverCamera();
    	}
    }    
    public Image getImage() {
         NIVision.IMAQdxGrab(m_id, m_frame, 1);
        return m_frame;
    }
    
// targeting code
	   public class ParticleReport implements Comparator<ParticleReport>, Comparable<ParticleReport>{
			double PercentAreaToImageArea;
			double Area;
			double BoundingRectLeft;
			double BoundingRectTop;
			double BoundingRectRight;
			double BoundingRectBottom;
			  
			   public int compareTo(ParticleReport r)
			{
				return (int)(r.Area - this.Area);
			}
			
			public int compare(ParticleReport r1, ParticleReport r2)
			{
				return (int)(r1.Area - r2.Area);
			}
		};
		

		//Structure to represent the scores for the various tests used for target identification
		public class Scores {
			double Area;
			double Aspect;
		};

		Image m_binaryFrame;
		int imaqError;
	    boolean filteredDashboard;

		NIVision.Range TOTE_HUE_RANGE = new NIVision.Range(101, 64);	//Default hue range for yellow tote
		NIVision.Range TOTE_SAT_RANGE = new NIVision.Range(88, 255);	//Default saturation range for yellow tote
		NIVision.Range TOTE_VAL_RANGE = new NIVision.Range(134, 255);	//Default value range for yellow tote
		double AREA_MINIMUM = 0.5; //Default Area minimum for particle as a percentage of total image area
	    
	    
}

